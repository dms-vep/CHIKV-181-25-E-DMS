""" 
Snakemake pipeline for the nextstrain analysis of CHIKV.
Author: Will Hannon 
"""

#### ----------------------- Imports ----------------------- ####

import pandas as pd 
from os.path import join

#### -------------------- Configuration -------------------- ####

configfile: "configuration/pipeline.yaml"

#### ----------------------- Targets ----------------------- ####

rule all:
    input:
        join(config['sequence_dir'], "metadata.csv")


#### ------------------------ Rules ------------------------ ####


rule download_records:
    """
    Download all sequence records from GenBank.
    """
    input: 
        config['accessions']['all']
    output: 
        join(config['sequence_dir'], "records.pickle")
    params:
        include=config['accessions']['include'],
    conda: "nextstrain"
    log: join(config['log_dir'], "download-records.log")
    shell:
        """
        python workflow/scripts/download-records.py \
            --accessions {input} \
            --include {params.include} \
            --output {output} \
            &>> {log}
        """


rule parse_feature:
    """
    Parse the target sequence feature from all sequences using alignment.
    """
    input: 
        join(config['sequence_dir'], "records.pickle")
    output: 
        join(config['sequence_dir'], "parsed_features.csv")
    params:
        feature=config['feature'],
        reference=config['accessions']['library'],
    conda: "nextstrain"
    log: join(config['log_dir'], "parse-feature.log")
    shell:
        """
        python workflow/scripts/parse-feature.py \
            --input {input} \
            --feature "{params.feature}" \
            --reference {params.reference} \
            --output {output} \
            &>> {log}
        """


rule filter_records:
    """
    Filter the records base on feature alignment.
    """
    input: 
        join(config['sequence_dir'], "parsed_features.csv")
    output: 
        join(config['sequence_dir'], "filtered_features.csv")
    params:
        min_feature_length=config['filter']['min_feature_length'],
        max_feature_length=config['filter']['max_feature_length'],
        max_ambiguous_positions=config['filter']['max_ambiguous_positions'],
        remove_duplicates=config['filter']['remove_duplicates'],
        min_alignment_score=config['filter']['min_alignment_score'],
    conda: "nextstrain"
    log: join(config['log_dir'], "filter-records.log")
    shell:
        """
        python workflow/scripts/filter-records.py \
            --input {input} \
            --min_feature_length {params.min_feature_length} \
            --max_feature_length {params.max_feature_length} \
            --max_ambiguous_positions {params.max_ambiguous_positions} \
            --remove_duplicates {params.remove_duplicates} \
            --min_alignment_score {params.min_alignment_score} \
            --output {output} \
            &>> {log}
        """


rule extract_metadata:
    """
    Extract the metadata for the filtered accessions.
    """
    input: 
        records=join(config['sequence_dir'], "records.pickle"),
        filtered=join(config['sequence_dir'], "filtered_features.csv")
    output: 
        join(config['sequence_dir'], "metadata.csv")
    conda: "nextstrain"
    log: join(config['log_dir'], "extract-metadata.log")
    shell:
        """
        python workflow/scripts/extract-metadata.py \
            --records {input.records} \
            --filtered {input.filtered} \
            --output {output} \
            &>> {log}
        """
